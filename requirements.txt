numpy>=1.21.0
opencv-python>=4.7.0
mediapipe>=0.10.0
requests>=2.28.0
faster-whisper>=0.9.0  # Using CTranslate2-based implementation (10-15x faster on GPU)
sounddevice>=0.4.6
webrtcvad>=2.0.10
azure-cognitiveservices-speech>=1.30.0 # For Azure Speech-to-Text

# Server dependencies
fastapi>=0.96.0
uvicorn>=0.22.0
python-multipart>=0.0.6  # For handling form data
soundfile>=0.12.1  # For audio file processing
scipy>=1.10.1  # For audio resampling
pydantic>=1.10.0  # Data validation
torch>=2.0.0
openai>=1.3.0  # For OpenAI API access and LLM integration

# Add these dependencies for noise filtering
scipy>=1.8.0
noisereduce>=2.0.1

# Whisper model size notes:
# - tiny.en: ~75MB - Fastest, least accurate
# - base.en: ~150MB
# - small.en: ~500MB
# - medium.en: ~1.5GB
# - large-v3: ~3GB - Slowest, most accurate
# 
# Requirements increase with larger models:
# - tiny & base: 2GB RAM, dual-core CPU
# - small: 4GB RAM, quad-core CPU
# - medium: 8GB RAM, modern CPU with 6+ cores
# - large: 16GB RAM, modern CPU with 8+ cores or GPU 